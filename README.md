# LEGO-Detection Project README

## Project Overview

LEGO-Detection is a YOLO-based object detection project designed to detect different LEGO elements such as bricks, figures, and hands in images. It uses the Ultralytics YOLOv8 framework and is implemented in Python.

---

## Folder Structure

```
LEGO-Detection/
├── analyze_performance_full.py    # Script to evaluate model performance
├── lego_dataset/                  # Dataset folder
│   ├── train/                     # Training images and labels
│   ├── valid/                     # Validation images and labels
│   ├── test/                     # Testing images
│   └── labels.cache               # Cached label info for fast validation
├── runs/                          # Stores training and validation outputs
│   ├── detect/                    # Detection results
│   │   ├── train/                 # Training logs and best weights
│   │   ├── val1/                  # First validation results
│   │   ├── val2/                  # Second validation results
│   │   └── val3/                  # Third validation results
├── venv/                          # Python virtual environment
└── README.md                      
```

### Folder Details

- **analyze\_performance\_full.py**: Evaluates the YOLO model on validation images and outputs precision, recall, and mAP metrics. Must be run after training.
- **lego\_dataset/**: Contains training and validation images along with their YOLO labels. `labels.cache` speeds up evaluation.
- **runs/**: Auto-generated by YOLO during training and validation. `train/` contains the trained weights, while `val*/` folders contain validation outputs.
- **venv/**: Python virtual environment to isolate dependencies.
- **requirements.txt**: Lists all Python packages required, e.g., ultralytics, torch, matplotlib.

---

## Setup Instructions

1. **Clone the repository** (or ensure all files are in a local folder).
2. **Navigate to project folder**:

```powershell
cd F:\Downloads\LEGO-Detection
```

3. **Create a virtual environment**:

```powershell
python -m venv venv
```

4. **Activate the virtual environment**:

- Windows:

```powershell
venv\Scripts\activate
```

- Mac/Linux:

```bash
source venv/bin/activate
```

5. **Install dependencies**:

```powershell
pip install -r requirements.txt
```

---

## Training the Model

1. **Start training using YOLO**:

```powershell
yolo task=detect mode=train model=yolov8n.pt data=lego_dataset/train epochs=50 imgsz=640
```

2. Training logs, plots, and the `best.pt` model weights will be saved in `runs/detect/train/`.

---

## Analyzing Model Performance

1. **Run the evaluation script**:

```powershell
python analyze_performance_full.py
```

2. The script will:
   - Load the trained YOLO model.
   - Validate it on images in `lego_dataset/valid/`.
   - Compute metrics: Precision, Recall, mAP\@0.5, mAP\@0.5-0.95.
3. **Results** are stored in folders like `runs/detect/val1`, `val2`, or `val3`.

**Notes/Troubleshooting:**

- `FileNotFoundError: No 'train*' folders found` → Ensure you have trained the model and `runs/detect/train/weights/best.pt` exists.
- `Label class X exceeds dataset class count` → Fix your label `.txt` files so that class indices range from `0` to `num_classes-1`.
- Mixed segment/detect datasets warning → Only boxes are used; ensure your dataset is consistent.

---

## Tips

- Keep your dataset organized in `train/` and `valid/`.
- Always check for corrupt images or label mismatches.
- Validate your model after each training cycle to ensure improvements.
- Use `venv` to prevent dependency conflicts.

---

## References

- YOLOv8 Documentation: [https://docs.ultralytics.com/](https://docs.ultralytics.com/)
- Ultralytics GitHub: [https://github.com/ultralytics/ultralytics](https://github.com/ultralytics/ultralytics)

---

**End of README**

Amogha Sri Kommera
